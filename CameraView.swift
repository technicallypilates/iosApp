import SwiftUI
import AVFoundation
import Vision
import UIKit

struct CameraView: UIViewRepresentable {
    @Binding var poseLabel: String
    @Binding var poseColor: Color
    @Binding var startDetection: Bool
    var selectedRoutine: Routine  // ðŸ‘ˆ NEW

    class CameraCoordinator: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {
        var parent: CameraView
        let poseEstimator = PoseEstimator()

        init(parent: CameraView) {
            self.parent = parent
        }

        func captureOutput(_ output: AVCaptureOutput,
                           didOutput sampleBuffer: CMSampleBuffer,
                           from connection: AVCaptureConnection) {

            guard parent.startDetection else { return } // â›”ï¸ Ignore frames until detection starts
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

            poseEstimator.performPoseDetection(pixelBuffer: pixelBuffer) { observations, predictedLabel in
                guard let first = observations.first else { return }

                let angles = self.poseEstimator.computeAngles(from: first)

                // âœ… Print angles (optional debugging)
                if let leftHip = angles["leftHipAngle"] {
                    print("ðŸ¦µ Left Hip Angle: \(Int(leftHip))Â°")
                }
                if let rightHip = angles["rightHipAngle"] {
                    print("ðŸ¦µ Right Hip Angle: \(Int(rightHip))Â°")
                }
                if let leftElbow = angles["leftElbowAngle"] {
                    print("ðŸ’ª Left Elbow Angle: \(Int(leftElbow))Â°")
                }
                if let rightElbow = angles["rightElbowAngle"] {
                    print("ðŸ’ª Right Elbow Angle: \(Int(rightElbow))Â°")
                }

                // âœ… Log selected routine (optional)
                print("ðŸ“‹ Routine in use: \(self.parent.selectedRoutine.rawValue)")

                // âœ… Update label and color in UI thread
                DispatchQueue.main.async {
                    if let label = predictedLabel {
                        self.parent.poseLabel = label

                        if label.lowercased().contains("correct") {
                            self.parent.poseColor = .green
                        } else {
                            self.parent.poseColor = .red
                            self.triggerVibration()
                        }
                    } else {
                        self.parent.poseLabel = "Analyzing..."
                        self.parent.poseColor = .gray
                    }
                }
            }
        }

        /// ðŸ“³ Haptic vibration for incorrect pose
        private func triggerVibration() {
            let generator = UINotificationFeedbackGenerator()
            generator.notificationOccurred(.error)
        }
    }

    func makeCoordinator() -> CameraCoordinator {
        return CameraCoordinator(parent: self)
    }

    func makeUIView(context: Context) -> UIView {
        let view = UIView()
        let session = AVCaptureSession()
        session.sessionPreset = .high

        guard let device = AVCaptureDevice.default(for: .video),
              let input = try? AVCaptureDeviceInput(device: device),
              session.canAddInput(input) else {
            return view
        }

        session.addInput(input)

        let output = AVCaptureVideoDataOutput()
        output.setSampleBufferDelegate(context.coordinator, queue: DispatchQueue(label: "videoQueue"))
        session.addOutput(output)

        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.videoGravity = .resizeAspectFill
        previewLayer.frame = UIScreen.main.bounds
        view.layer.addSublayer(previewLayer)

        session.startRunning()
        return view
    }

    func updateUIView(_ uiView: UIView, context: Context) {
        // You could use this to update the view dynamically later if needed
    }
}

